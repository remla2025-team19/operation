---
- hosts: all
  vars:
    metallb_version: "v0.14.9"
  environment:
    KUBECONFIG: /home/vagrant/.kube/config
  tasks:
    # Step 20
    - name: Download MetalLB manifest from GitHub
      ansible.builtin.get_url:
        url: "https://raw.githubusercontent.com/metallb/metallb/{{ metallb_version }}/config/manifests/metallb-native.yaml"
        dest: /home/vagrant/metallb-native.yaml
        owner: vagrant
        group: vagrant
        mode: "0644"

    # Use failed_when instead of ignore_errors to avoid fail tasks
    - name: Check if MetalLB is already deployed
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Namespace
        name: metallb-system
      register: metallb_check
      failed_when: false
      become: false

    - name: Print metallb_check status
      ansible.builtin.debug:
        msg: "MetalLB namespace {{ 'exists' if metallb_check.resources else 'not found' }}"
      become: false

    - name: Apply MetalLB manifest
      kubernetes.core.k8s:
        src: /home/vagrant/metallb-native.yaml
        state: present
      when: not metallb_check.resources
      become: false

    - name: Wait for MetalLB pods to be ready
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        namespace: metallb-system
        label_selectors:
          - app=metallb
          - component=controller
        wait: true
        wait_condition:
          type: Ready
          status: "True"
        wait_timeout: 60
      become: false
      when: not metallb_check.resources
      ignore_errors: true
      retries: 3
      delay: 10

    - name: Create MetalLB configuration
      ansible.builtin.copy:
        dest: /home/vagrant/metallb-config.yaml
        content: |
          apiVersion: metallb.io/v1beta1
          kind: IPAddressPool
          metadata:
            name: default-pool
            namespace: metallb-system
          spec:
            addresses:
            - 192.168.56.90-192.168.56.99
          ---
          apiVersion: metallb.io/v1beta1
          kind: L2Advertisement
          metadata:
            name: default
            namespace: metallb-system
          spec:
            ipAddressPools:
            - default-pool
        owner: vagrant
        group: vagrant
        mode: "0644"

    - name: Apply MetalLB configuration
      kubernetes.core.k8s:
        src: /home/vagrant/metallb-config.yaml
        state: present
      become: false

    # Step 21
    - name: Install ingress-nginx with helm
      kubernetes.core.helm:
        # Note: Add ingressClassName:"nginx" to the spec of any Ingress that should use this new IngressController.
        name: ingress-nginx
        chart_ref: ingress-nginx
        chart_repo_url: https://kubernetes.github.io/ingress-nginx
        release_namespace: ingress-nginx
        create_namespace: true
        values:
          controller:
            service:
              loadBalancerIP: 192.168.56.90
      become: false

    - name: Wait for ingress-nginx webhook
      kubernetes.core.k8s_info:
        api_version: apps/v1
        kind: Deployment
        name: ingress-nginx-controller
        namespace: ingress-nginx
        wait: true
        wait_condition:
          type: Available
          status: "True"
        wait_timeout: 300
      become: false

    # Step 22
    - name: Check if Kubernetes Dashboard is already installed
      kubernetes.core.helm_info:
        name: kubernetes-dashboard
        release_namespace: kubernetes-dashboard
      register: dashboard_check
      failed_when: false
      become: false

    - name: Install Kubernetes Dashboard with helm
      kubernetes.core.helm:
        name: kubernetes-dashboard
        chart_ref: kubernetes-dashboard
        chart_repo_url: https://kubernetes.github.io/dashboard/
        release_namespace: kubernetes-dashboard
        create_namespace: true
        release_values:
          app:
            settings:
              authMode: token
          auth:
            mode: token
      when: dashboard_check.status is not defined or dashboard_check.status.status != "deployed"
      become: false

    - name: Copy Kubernetes manifests to VM
      ansible.builtin.copy:
        src: "{{ playbook_dir }}/k8s/"
        dest: /home/vagrant/k8s/
        owner: vagrant
        group: vagrant
        mode: "0644"
      become: false

    - name: Apply dashboard.yml to set up admin user
      kubernetes.core.k8s:
        src: /home/vagrant/k8s/dashboard.yml
        state: present
      become: false

    # Step 23: Install Istio
    - name: Determine Istio architecture suffix
      ansible.builtin.set_fact:
        istio_arch_suffix: "{{ 'amd64' if ansible_facts.architecture == 'x86_64' else 'arm64' if ansible_facts.architecture == 'aarch64' else 'unsupported' }}"

    - name: Fail if architecture is unsupported
      ansible.builtin.fail:
        msg: "Unsupported architecture: {{ ansible_facts.architecture }}. Istio download is only configured for x86_64 (amd64) and aarch64 (arm64)."
      when: istio_arch_suffix == 'unsupported'

    - name: Download Istio 1.25.2
      ansible.builtin.get_url:
        url: "https://github.com/istio/istio/releases/download/1.25.2/istio-1.25.2-linux-{{ istio_arch_suffix }}.tar.gz"
        dest: "/home/vagrant/istio-1.25.2-linux-{{ istio_arch_suffix }}.tar.gz"
        owner: vagrant
        group: vagrant
        mode: "0644"

    - name: Extract Istio
      ansible.builtin.unarchive:
        src: "/home/vagrant/istio-1.25.2-linux-{{ istio_arch_suffix }}.tar.gz"
        dest: /home/vagrant
        remote_src: true
        owner: vagrant
        group: vagrant

    - name: Install istioctl to /usr/local/bin
      ansible.builtin.copy:
        src: /home/vagrant/istio-1.25.2/bin/istioctl
        dest: /usr/local/bin/istioctl
        mode: "0755"
        owner: root
        group: root
        remote_src: yes
      become: yes

    - name: Create IstioOperator configuration for MetalLB
      ansible.builtin.copy:
        dest: /home/vagrant/istio-config.yaml
        content: |
          apiVersion: install.istio.io/v1alpha1
          kind: IstioOperator
          metadata:
            name: control-plane
          spec:
            values:
              gateways:
                istio-ingressgateway:
                  loadBalancerIP: 192.168.56.91
        owner: vagrant
        group: vagrant
        mode: "0644"

    - name: Check if Istio CRD existence
      kubernetes.core.k8s_info:
        api_version: apiextensions.k8s.io/v1
        kind: CustomResourceDefinition
        name: gateways.networking.istio.io
      register: istio_check
      failed_when: false
      become: false

    # NOTE: The shell still does not detect istioctl in path
    - name: Install Istio with custom configuration
      ansible.builtin.shell:
        cmd: istioctl install -y -f /home/vagrant/istio-config.yaml
      become: false
      when: not istio_check.resources

    - name: Wait for Istio pods to be ready
      kubernetes.core.k8s_info:
        api_version: apps/v1
        kind: Deployment
        namespace: istio-system
        wait: true
        wait_condition:
          type: Available
          status: "True"
        wait_timeout: 300
      become: false

    - name: Install Istio Prometheus addon
      kubernetes.core.k8s:
        src: /home/vagrant/istio-1.25.2/samples/addons/prometheus.yaml
        state: present
      become: false

    - name: Install Istio Jaeger addon
      kubernetes.core.k8s:
        src: /home/vagrant/istio-1.25.2/samples/addons/jaeger.yaml
        state: present
      become: false

    - name: Install Istio Kiali addon
      kubernetes.core.k8s:
        src: /home/vagrant/istio-1.25.2/samples/addons/kiali.yaml
        state: present
      become: false

    - name: Wait for Istio addons to be ready
      kubernetes.core.k8s_info:
        api_version: apps/v1
        kind: Deployment
        namespace: istio-system
        wait: true
        wait_condition:
          type: Available
          status: "True"
        wait_timeout: 300
      become: false
      ignore_errors: true

    # Configure Istio for Canary Deployment
    - name: Enable Istio injection on default namespace
      kubernetes.core.k8s:
        api_version: v1
        kind: Namespace
        name: default
        definition:
          metadata:
            labels:
              istio-injection: "enabled"
        state: present
      become: false

      # TODO: install helm chart here
    - name: Copy Helm Chart to VM
      ansible.builtin.copy:
        src: "{{ playbook_dir }}/../helm"
        dest: /home/vagrant
        owner: vagrant
        group: vagrant
        mode: "0755"
      become: false

    - name: Add Prometheus Community Helm repository
      kubernetes.core.helm_repository:
        name: prometheus-community
        repo_url: https://prometheus-community.github.io/helm-charts
      become: false

    - name: Install Prometheus Operator
      kubernetes.core.helm:
        name: prometheus-operator
        chart_ref: prometheus-community/kube-prometheus-stack
        release_namespace: prometheus-operator
        create_namespace: true
        wait: true
        wait_timeout: 180s
      become: false

    - name: Wait for ServiceMonitor CRD to be available
      kubernetes.core.k8s_info:
        api_version: apiextensions.k8s.io/v1
        kind: CustomResourceDefinition
        name: servicemonitors.monitoring.coreos.com
        wait: true
        wait_condition:
          type: Established
          status: "True"
        wait_timeout: 300
      become: false

    - name: Install kube-prometheus-stack with values
      kubernetes.core.helm:
        name: monitoring
        chart_ref: kube-prometheus-stack
        chart_repo_url: https://prometheus-community.github.io/helm-charts
        release_namespace: monitoring
        create_namespace: true
        values_files:
          - "/home/vagrant/helm/sentiment-analyzer/grafana-values.yaml"
      become: false

    - name: Install Ingress-based Sentiment Analyzer Helm Chart
      kubernetes.core.helm:
        name: ingress-sentiment-analyzer
        chart_ref: /home/vagrant/helm/sentiment-analyzer
        release_namespace: default
        values:
          istio:
            enabled: false
          app:
            ingress:
              host: restaurant.local

    - name: Install Gateway-based Sentiment Analyzer Helm Chart
      kubernetes.core.helm:
        name: istio-sentiment-analyzer
        chart_ref: /home/vagrant/helm/sentiment-analyzer
        release_namespace: default
        values:
          model:
            service:
              port: 5001
          app:
            ingress:
              host: app.local
      become: false

    - name: Deploy and configure rate limit service
      kubernetes.core.k8s:
        src: /home/vagrant/k8s/istio-rate-limit.yml
        state: present
        wait: true
        wait_timeout: 180
      become: false

    - name: Wait for app deployments to be ready
      kubernetes.core.k8s_info:
        api_version: apps/v1
        kind: Deployment
        label_selectors:
          - app=istio-sentiment-analyzer-app
        wait: true
        wait_condition:
          type: Available
          status: "True"
        wait_timeout: 300
      become: false

    - name: Wait for model deployments to be ready
      kubernetes.core.k8s_info:
        api_version: apps/v1
        kind: Deployment
        label_selectors:
          - app=istio-sentiment-analyzer-model
        wait: true
        wait_condition:
          type: Available
          status: "True"
        wait_timeout: 300
      become: false

    - name: Verify Istio sidecar injection
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        label_selectors:
          - app=istio-sentiment-analyzer-app
      register: app_pods
      become: false

    - name: Display app containers with sidecars
      ansible.builtin.debug:
        msg: "App containers: {{ app_pods.resources | map(attribute='status.containerStatuses') | flatten | map(attribute='name') | list | join(', ') }}"
      become: false
      when: app_pods.resources | length > 0
